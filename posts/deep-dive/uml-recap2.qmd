---
title: "Machine Learning Recap 2 Gradient Boosters and Random Forests"
author: "Xiaochuan Yang"
date: "2023-11-?"
categories: [code, machine learning]
draft: true
toc: true
number-sections: false
---

\def\PP{\mathbb{P}}
\def\VAR{\mathrm{VaR}}
\def\RR{\mathbb{R}}
\def\EE{\mathbb{E}}


In this post, we focus on ML algorithms for classification, a common task in many real-life applications. For instance, in the series of [credit risk modelling](crm2-ml.qmd), we demonstrated how estimating the probability of default can be casted as a  a classification problmem, i.e. whether a loan borrower will go into default.

[Recalling](uml-recap1.qmd) some notation, we have  

- an example space $\mathcal X$  
- a label space $\mathcal Y$
-  a collection of hypotheses $h: \mathcal X \to \mathcal Y$, making up the hypothesis class  (inductive bias), from which we want to pick a predictor
-  a loss function $\ell: \mathcal Y \times \mathcal Y \to \RR_+$, quantifying how good or bad a prediction $\hat y$ is compared to the ground truth label $y$

:::{.callout-important}
We are given an independent and identically distributed input-output pairs 
$S^0 = \{(x_i,y_i), i=[m]\}\subset \mathcal X\times\mathcal Y$ with distribution $D$. 
:::


We adopt a validation approach, where we minimise the empirical risk (ERM) with data in the train split $S$, and evaluate the true loss with data in the validation split $V$. 


$$
h_{S} \in \mathrm{argmin}_{h\in\mathcal H} L_{S}(h), \quad L_{S}(h):= \frac{1}{m}\sum_{i=1}^m \ell(h(x_i),y_i)
$$



Now consider $\mathcal H$. It is sometimes beneficial to predict a probability mass function (pmf) over the $k$ classes. From the pmf, a label can be obtained by taking argmax. In other words, the range of $h\in\mathcal H$ is assumed to be $\{y\in\RR^k: y_i\ge 0, y_1+...+y_k=1\}$. In this scenario, the cross entropy loss is often a good choice
$$
XE(p,\hat p) =  - \sum_{i=1}^k p_i \log(\hat p_i)
$$

Why don't we use the 0-1 loss? This seems quite natural if the prediction accuracy is what we care the most.
$$
\ell_{0-1}(y,\hat y) = \mathbb{I}(y\neq \hat y)
$$
The principle reason is that this loss is non-convex and discrete, making it difficult to optimise (rememeber that we are looking for an ERM on the train split). 

Next we consider tree algorithms. We review the time and space complexity for training and deploying these models.

## Decision Trees

The precedure of decision tree is simple and humane.

```{python}
class Node:
    def __init__(self, feature=None, threshold=None, left=None, right=None,*, value=None):
        self.feature = feature
        self.threshold = threshold
        self.left = left
        self.right = right
        self.value=value

class DecisionTree:
    def __init__(self): self.root = None

    def fit(self,X,y): self.root = self._build_tree(X,y)

    def _best_split(self,X,y):
    # return best split feature, threshold, idx of left samples 
        pass
    def is_pure(y): pass

    def _build_tree(self, X, y):
        if is_pure(y): return Node(value=y[0])
        j, theta, idx = self._best_split(X,y)
        root = Node(j,theta)
        root.left = self._build_tree(X[idx],y[idx])
        root.right = self._build_tree(X[~idx],y[~idx])
        return root

    def predict(self, X): 
        head = self.root
        ys=[]
        for x in X:
            while head.left or head.right:
                if x[head.feature]<head.threshold: head = head.left
                else: head=head.right
            ys.append(head.value)
        return ys
            

```


## Gradient Boosting Decision Trees

## Random Forest