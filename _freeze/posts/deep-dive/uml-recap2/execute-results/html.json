{
  "hash": "92c965e716f9a1cc0e61fa6e33e60f19",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Machine Learning Recap 2 Gradient Boosters and Random Forests\"\nauthor: \"Xiaochuan Yang\"\ndate: \"2023-11-?\"\ncategories: [code, machine learning]\ndraft: true\ntoc: true\nnumber-sections: false\n---\n\n\\def\\PP{\\mathbb{P}}\n\\def\\VAR{\\mathrm{VaR}}\n\\def\\RR{\\mathbb{R}}\n\\def\\EE{\\mathbb{E}}\n\n\nIn this post, we focus on ML algorithms for classification, a common task in many real-life applications. For instance, in the series of [credit risk modelling](crm2-ml.qmd), we demonstrated how estimating the probability of default can be casted as a  a classification problmem, i.e. whether a loan borrower will go into default.\n\n[Recalling](uml-recap1.qmd) some notation, we have  \n\n- an example space $\\mathcal X$  \n- a label space $\\mathcal Y$\n-  a collection of hypotheses $h: \\mathcal X \\to \\mathcal Y$, making up the hypothesis class  (inductive bias), from which we want to pick a predictor\n-  a loss function $\\ell: \\mathcal Y \\times \\mathcal Y \\to \\RR_+$, quantifying how good or bad a prediction $\\hat y$ is compared to the ground truth label $y$\n\n:::{.callout-important}\nWe are given an independent and identically distributed input-output pairs \n$S^0 = \\{(x_i,y_i), i=[m]\\}\\subset \\mathcal X\\times\\mathcal Y$ with distribution $D$. \n:::\n\n\nWe adopt a validation approach, where we minimise the empirical risk (ERM) with data in the train split $S$, and evaluate the true loss with data in the validation split $V$. \n\n\n$$\nh_{S} \\in \\mathrm{argmin}_{h\\in\\mathcal H} L_{S}(h), \\quad L_{S}(h):= \\frac{1}{m}\\sum_{i=1}^m \\ell(h(x_i),y_i)\n$$\n\n\n\nNow consider $\\mathcal H$. It is sometimes beneficial to predict a probability mass function (pmf) over the $k$ classes. From the pmf, a label can be obtained by taking argmax. In other words, the range of $h\\in\\mathcal H$ is assumed to be $\\{y\\in\\RR^k: y_i\\ge 0, y_1+...+y_k=1\\}$. In this scenario, the cross entropy loss is often a good choice\n$$\nXE(p,\\hat p) =  - \\sum_{i=1}^k p_i \\log(\\hat p_i)\n$$\n\nWhy don't we use the 0-1 loss? This seems quite natural if the prediction accuracy is what we care the most.\n$$\n\\ell_{0-1}(y,\\hat y) = \\mathbb{I}(y\\neq \\hat y)\n$$\nThe principle reason is that this loss is non-convex and discrete, making it difficult to optimise (rememeber that we are looking for an ERM on the train split). \n\nNext we consider tree algorithms. We review the time and space complexity for training and deploying these models.\n\n## Decision Trees\n\nThe precedure of decision tree is simple and humane.\n\n::: {#9a675949 .cell execution_count=1}\n``` {.python .cell-code}\nclass Node:\n    def __init__(self, feature=None, threshold=None, left=None, right=None,*, value=None):\n        self.feature = feature\n        self.threshold = threshold\n        self.left = left\n        self.right = right\n        self.value=value\n\nclass DecisionTree:\n    def __init__(self): self.root = None\n\n    def fit(self,X,y): self.root = self._build_tree(X,y)\n\n    def _best_split(self,X,y):\n    # return best split feature, threshold, idx of left samples \n        pass\n    def is_pure(y): pass\n\n    def _build_tree(self, X, y):\n        if is_pure(y): return Node(value=y[0])\n        j, theta, idx = self._best_split(X,y)\n        root = Node(j,theta)\n        root.left = self._build_tree(X[idx],y[idx])\n        root.right = self._build_tree(X[~idx],y[~idx])\n        return root\n\n    def predict(self, X): \n        head = self.root\n        ys=[]\n        for x in X:\n            while head.left or head.right:\n                if x[head.feature]<head.threshold: head = head.left\n                else: head=head.right\n            ys.append(head.value)\n        return ys\n\n```\n:::\n\n\n## Gradient Boosting Decision Trees\n\n## Random Forest\n\n",
    "supporting": [
      "uml-recap2_files"
    ],
    "filters": [],
    "includes": {}
  }
}